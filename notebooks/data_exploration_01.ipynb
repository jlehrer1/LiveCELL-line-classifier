{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e394a2d6",
   "metadata": {},
   "source": [
    "# Data Exploration 01\n",
    "\n",
    "In this notebook, we'll try making a CNN for cell line classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d53854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch\n",
    "import os \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3624c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"A172\": \"Glioblastoma\",\n",
    "    \"BT474\": \"Ductal Carcinoma\",\n",
    "    \"BV2\": \"Microglial\",\n",
    "    \"Huh7\": \"Tumorigenic\",\n",
    "    \"MCF7\": \"Breast Cancer\",\n",
    "    \"SHSY5Y\": \"Neuroblastoma\",\n",
    "    \"SkBr3\": \"Adenocarcinoma\",\n",
    "    \"SKOV3\": \"Adenocarcinoma\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c23ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images of Glioblastoma is 608\n",
      "Number of images of Ductal Carcinoma is 672\n",
      "Number of images of Microglial is 608\n",
      "Number of images of Tumorigenic is 600\n",
      "Number of images of Breast Cancer is 735\n",
      "Number of images of Neuroblastoma is 704\n",
      "Number of images of Adenocarcinoma is 704\n",
      "Number of images of Adenocarcinoma is 608\n"
     ]
    }
   ],
   "source": [
    "for t in mapping:\n",
    "    num_in = len([f for f in os.listdir(os.path.join('../images/', t))])\n",
    "    print(f'Number of images of {mapping[t]} is {num_in}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767821d",
   "metadata": {},
   "source": [
    "Now, we have to create the labels file. We'll have a column with the true label name, and another with an integer encoded representation since PyTorch doesn't encode strings automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "04f1cfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A172/A172_Phase_A7_1_00d08h00m_3.tif</th>\n",
       "      <td>Glioblastoma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A172/A172_Phase_A7_2_02d04h00m_1.tif</th>\n",
       "      <td>Glioblastoma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A172/A172_Phase_B7_1_03d00h00m_3.tif</th>\n",
       "      <td>Glioblastoma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A172/A172_Phase_C7_2_01d04h00m_3.tif</th>\n",
       "      <td>Glioblastoma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A172/A172_Phase_C7_1_01d00h00m_2.tif</th>\n",
       "      <td>Glioblastoma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             label  class\n",
       "filename                                                 \n",
       "A172/A172_Phase_A7_1_00d08h00m_3.tif  Glioblastoma      3\n",
       "A172/A172_Phase_A7_2_02d04h00m_1.tif  Glioblastoma      3\n",
       "A172/A172_Phase_B7_1_03d00h00m_3.tif  Glioblastoma      3\n",
       "A172/A172_Phase_C7_2_01d04h00m_3.tif  Glioblastoma      3\n",
       "A172/A172_Phase_C7_1_01d00h00m_2.tif  Glioblastoma      3"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "df = pd.DataFrame(columns=['label'])\n",
    "df.index.name = 'filename'\n",
    "for t in mapping:\n",
    "    for f in os.listdir(os.path.join('../images/', t)):\n",
    "        df.loc[os.path.join(t, f), :] = mapping[t]\n",
    "\n",
    "df['class'] = le.fit_transform(df['label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6aa38269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A172\n",
      "BT474\n",
      "BV2\n",
      "Huh7\n",
      "MCF7\n",
      "SHSY5Y\n",
      "SkBr3\n",
      "SKOV3\n"
     ]
    }
   ],
   "source": [
    "for k in mapping:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c36f6757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A172/A172_Phase_A7_1_00d08h00m_3.tif</td>\n",
       "      <td>Glioblastoma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A172/A172_Phase_A7_2_02d04h00m_1.tif</td>\n",
       "      <td>Glioblastoma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A172/A172_Phase_B7_1_03d00h00m_3.tif</td>\n",
       "      <td>Glioblastoma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A172/A172_Phase_C7_2_01d04h00m_3.tif</td>\n",
       "      <td>Glioblastoma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A172/A172_Phase_C7_1_01d00h00m_2.tif</td>\n",
       "      <td>Glioblastoma</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>SKOV3/SKOV3_Phase_E4_1_01d04h00m_2.tif</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5235</th>\n",
       "      <td>SKOV3/SKOV3_Phase_E4_2_01d12h00m_4.tif</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>SKOV3/SKOV3_Phase_G4_1_00d20h00m_1.tif</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>SKOV3/SKOV3_Phase_H4_2_01d00h00m_3.tif</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>SKOV3/SKOV3_Phase_H4_1_01d04h00m_2.tif</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5239 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename           label  class\n",
       "0       A172/A172_Phase_A7_1_00d08h00m_3.tif    Glioblastoma      3\n",
       "1       A172/A172_Phase_A7_2_02d04h00m_1.tif    Glioblastoma      3\n",
       "2       A172/A172_Phase_B7_1_03d00h00m_3.tif    Glioblastoma      3\n",
       "3       A172/A172_Phase_C7_2_01d04h00m_3.tif    Glioblastoma      3\n",
       "4       A172/A172_Phase_C7_1_01d00h00m_2.tif    Glioblastoma      3\n",
       "...                                      ...             ...    ...\n",
       "5234  SKOV3/SKOV3_Phase_E4_1_01d04h00m_2.tif  Adenocarcinoma      0\n",
       "5235  SKOV3/SKOV3_Phase_E4_2_01d12h00m_4.tif  Adenocarcinoma      0\n",
       "5236  SKOV3/SKOV3_Phase_G4_1_00d20h00m_1.tif  Adenocarcinoma      0\n",
       "5237  SKOV3/SKOV3_Phase_H4_2_01d00h00m_3.tif  Adenocarcinoma      0\n",
       "5238  SKOV3/SKOV3_Phase_H4_1_01d04h00m_2.tif  Adenocarcinoma      0\n",
       "\n",
       "[5239 rows x 3 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('../images/labels.csv', index=True)\n",
    "pd.read_csv('../images/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42398038",
   "metadata": {},
   "source": [
    "Now that we've created a labels file, we can create the PyTorch dataset and generate our train-test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d0f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellDataset(Dataset):\n",
    "    def __init__(self, images_path, label_path):\n",
    "        self.images_path = images_path\n",
    "        self.labels = pd.read_csv(label_path)\n",
    "        self.tensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.labels.iloc[idx]['filename'], self.labels.iloc[idx]['class']\n",
    "        img = Image.open(os.path.join(self.images_path, img_path))\n",
    "        return self.tensor(img), label\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b99c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.4980, 0.5020, 0.4980,  ..., 0.4275, 0.4353, 0.4510],\n",
       "          [0.4941, 0.4980, 0.5137,  ..., 0.4157, 0.3647, 0.3922],\n",
       "          [0.4980, 0.4980, 0.5059,  ..., 0.3882, 0.4549, 0.4863],\n",
       "          ...,\n",
       "          [0.4941, 0.4941, 0.5020,  ..., 0.5020, 0.4980, 0.5059],\n",
       "          [0.5098, 0.5059, 0.5059,  ..., 0.4980, 0.4980, 0.5020],\n",
       "          [0.5098, 0.5059, 0.4980,  ..., 0.5059, 0.4980, 0.5020]]]),\n",
       " 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CellDataset('../images/', '../images/labels.csv')\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7cda9c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_size = int(0.80 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4617877",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = DataLoader(train, batch_size=8, num_workers=0)\n",
    "valdata = DataLoader(test, batch_size=8, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e773ee",
   "metadata": {},
   "source": [
    "Now that we've defined our data, we can build our CNN classifier and benchmark our results. We'll use PyTorch Lightning so we can run our model on the PRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c957de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            # nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(2,2),\n",
    "            # nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(2,2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd09db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65ae17bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5857280])\n",
      "torch.Size([8, 5857280])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/jsjcl0fn7w57s5mfr34b20pm0000gn/T/ipykernel_37027/2478172289.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(traindata, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        print(outputs.shape)\n",
    "        print(outputs.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04f6aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eee6db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science] *",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
