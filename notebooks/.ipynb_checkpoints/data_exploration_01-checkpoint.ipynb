{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1356f9e2",
   "metadata": {},
   "source": [
    "# Data Exploration 01\n",
    "\n",
    "In this notebook, we'll try making a CNN for cell line classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "61d53854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch\n",
    "import os \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3624c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"A172\": \"Glioblastoma\",\n",
    "    \"BT474\": \"Ductal Carcinoma\",\n",
    "    \"BV2\": \"Microglial\",\n",
    "    \"Huh7\": \"Tumorigenic\",\n",
    "    \"MCF7\": \"Breast Cancer\",\n",
    "    \"SHSY5Y\": \"Neuroblastoma\",\n",
    "    \"SkBr3\": \"Adenocarcinoma\",\n",
    "    \"SKOV3\": \"Adenocarcinoma\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "60c23ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images of Glioblastoma is 608\n",
      "Number of images of Ductal Carcinoma is 672\n",
      "Number of images of Microglial is 608\n",
      "Number of images of Tumorigenic is 600\n",
      "Number of images of Breast Cancer is 735\n",
      "Number of images of Neuroblastoma is 704\n",
      "Number of images of Adenocarcinoma is 704\n",
      "Number of images of Adenocarcinoma is 608\n"
     ]
    }
   ],
   "source": [
    "for t in mapping:\n",
    "    num_in = len([f for f in os.listdir(os.path.join('../images/', t))])\n",
    "    print(f'Number of images of {mapping[t]} is {num_in}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff215dd2",
   "metadata": {},
   "source": [
    "Now, we have to create the labels file. We'll have a column with the true label name, and another with an integer encoded representation since PyTorch doesn't encode strings automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "df = pd.DataFrame(columns=['label'])\n",
    "df.index.name = 'filename'\n",
    "for t in mapping:\n",
    "    for f in os.listdir(os.path.join('../images/', t)):\n",
    "        df.loc[os.path.join(t, f), :] = mapping[t]\n",
    "\n",
    "df['class'] = le.fit_transform(df['label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb2654f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A172/A172_Phase_A7_1_00d08h00m_3.tif</td>\n",
       "      <td>Glioblastoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A172/A172_Phase_A7_2_02d04h00m_1.tif</td>\n",
       "      <td>Glioblastoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A172/A172_Phase_B7_1_03d00h00m_3.tif</td>\n",
       "      <td>Glioblastoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A172/A172_Phase_C7_2_01d04h00m_3.tif</td>\n",
       "      <td>Glioblastoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A172/A172_Phase_C7_1_01d00h00m_2.tif</td>\n",
       "      <td>Glioblastoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>SKOV3/SKOV3_Phase_E4_1_01d04h00m_2.tif</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5235</th>\n",
       "      <td>SKOV3/SKOV3_Phase_E4_2_01d12h00m_4.tif</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>SKOV3/SKOV3_Phase_G4_1_00d20h00m_1.tif</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>SKOV3/SKOV3_Phase_H4_2_01d00h00m_3.tif</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>SKOV3/SKOV3_Phase_H4_1_01d04h00m_2.tif</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5239 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename           label\n",
       "0       A172/A172_Phase_A7_1_00d08h00m_3.tif    Glioblastoma\n",
       "1       A172/A172_Phase_A7_2_02d04h00m_1.tif    Glioblastoma\n",
       "2       A172/A172_Phase_B7_1_03d00h00m_3.tif    Glioblastoma\n",
       "3       A172/A172_Phase_C7_2_01d04h00m_3.tif    Glioblastoma\n",
       "4       A172/A172_Phase_C7_1_01d00h00m_2.tif    Glioblastoma\n",
       "...                                      ...             ...\n",
       "5234  SKOV3/SKOV3_Phase_E4_1_01d04h00m_2.tif  Adenocarcinoma\n",
       "5235  SKOV3/SKOV3_Phase_E4_2_01d12h00m_4.tif  Adenocarcinoma\n",
       "5236  SKOV3/SKOV3_Phase_G4_1_00d20h00m_1.tif  Adenocarcinoma\n",
       "5237  SKOV3/SKOV3_Phase_H4_2_01d00h00m_3.tif  Adenocarcinoma\n",
       "5238  SKOV3/SKOV3_Phase_H4_1_01d04h00m_2.tif  Adenocarcinoma\n",
       "\n",
       "[5239 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('../images/labels.csv', index=True)\n",
    "pd.read_csv('../images/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab247d3",
   "metadata": {},
   "source": [
    "Now that we've created a labels file, we can create the PyTorch dataset and generate our train-test split. However, since our labels are strings, we'll use `sklearn` preprocessing to convert them into numeric types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "531e5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellDataset(Dataset):\n",
    "    def __init__(self, images_path, label_path):\n",
    "        self.images_path = images_path\n",
    "        self.labels = pd.read_csv(label_path)\n",
    "        self.tensor = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.labels.iloc[idx]['filename'], self.labels.iloc[idx]['label']\n",
    "        img = Image.open(os.path.join(self.images_path, img_path))\n",
    "        return self.tensor(img), self.tensor(label)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4f0697e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CellDataset('../images/', '../images/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "23209463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_size = int(0.80 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "75932c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = DataLoader(train, batch_size=8, num_workers=0)\n",
    "valdata = DataLoader(test, batch_size=8, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3a1a2550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([8, 1, 520, 704])\n",
      "torch.Size([7, 1, 520, 704])\n"
     ]
    }
   ],
   "source": [
    "for X, _ in traindata:\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2622c8a3",
   "metadata": {},
   "source": [
    "Now that we've defined our data, we can build our CNN classifier and benchmark our results. We'll use PyTorch Lightning so we can run our model on the PRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "89697a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(520*704*4,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d0fccf1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f4ec512c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 7])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/jsjcl0fn7w57s5mfr34b20pm0000gn/T/ipykernel_58761/2568330639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[0;32m~/miniconda3/envs/base-data-science/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(traindata, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        print(outputs.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc7064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96056334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base-data-science]",
   "language": "python",
   "name": "conda-env-base-data-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
